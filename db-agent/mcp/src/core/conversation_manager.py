"""ç»Ÿä¸€å¯¹è¯å†å²ç®¡ç†å™¨ - æ”¯æŒè·¨å·¥å…·ç±»å‹çš„ä¼šè¯ç®¡ç†"""

import json
import sqlite3
import threading
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from .schemas import AgentState, Step


@dataclass
class ConversationMetadata:
    """å¯¹è¯å…ƒæ•°æ®"""
    thread_id: str
    user_id: str = "default"
    title: str = ""
    created_at: datetime = None
    updated_at: datetime = None
    tool_categories: List[str] = None
    tags: List[str] = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.updated_at is None:
            self.updated_at = datetime.now()
        if self.tool_categories is None:
            self.tool_categories = []
        if self.tags is None:
            self.tags = []


class ConversationManager:
    """ç»Ÿä¸€å¯¹è¯å†å²ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "conversations.db"):
        self.db_path = Path(db_path)
        self._lock = threading.Lock()
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    thread_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL DEFAULT 'default',
                    title TEXT,
                    created_at TIMESTAMP,
                    updated_at TIMESTAMP,
                    tool_categories TEXT,  -- JSON array
                    tags TEXT,            -- JSON array
                    state_data TEXT       -- JSON serialized AgentState
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversation_steps (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    thread_id TEXT NOT NULL,
                    step_index INTEGER NOT NULL,
                    step_data TEXT NOT NULL,  -- JSON serialized Step
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (thread_id) REFERENCES conversations (thread_id)
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_conversations_user_id 
                ON conversations (user_id)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_conversation_steps_thread_id 
                ON conversation_steps (thread_id)
            """)
    
    def create_conversation(self, thread_id: str, question: str, 
                          user_id: str = "default", 
                          tool_categories: List[str] = None,
                          max_steps: int = 12) -> AgentState:
        """åˆ›å»ºæ–°å¯¹è¯"""
        with self._lock:
            # åˆ›å»ºAgentState
            state = AgentState(
                question=question,
                max_steps=max_steps,
                steps=[],
                done=False
            )
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = ConversationMetadata(
                thread_id=thread_id,
                user_id=user_id,
                title=question[:50] + "..." if len(question) > 50 else question,
                tool_categories=tool_categories or []
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO conversations 
                    (thread_id, user_id, title, created_at, updated_at, tool_categories, tags, state_data)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    metadata.thread_id,
                    metadata.user_id,
                    metadata.title,
                    metadata.created_at,
                    metadata.updated_at,
                    json.dumps(metadata.tool_categories),
                    json.dumps(metadata.tags),
                    json.dumps(state.dict())
                ))
            
            return state
    
    def load_conversation(self, thread_id: str) -> Optional[AgentState]:
        """åŠ è½½å¯¹è¯çŠ¶æ€"""
        with self._lock:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT state_data FROM conversations WHERE thread_id = ?
                """, (thread_id,))
                
                row = cursor.fetchone()
                if not row:
                    return None
                
                try:
                    state_dict = json.loads(row[0])
                    return AgentState(**state_dict)
                except Exception as e:
                    print(f"Error loading conversation {thread_id}: {e}")
                    return None
    
    def save_conversation(self, thread_id: str, state: AgentState, 
                         tool_categories: List[str] = None):
        """ä¿å­˜å¯¹è¯çŠ¶æ€"""
        with self._lock:
            with sqlite3.connect(self.db_path) as conn:
                # æ›´æ–°ä¸»è®°å½•
                conn.execute("""
                    UPDATE conversations 
                    SET updated_at = ?, state_data = ?, tool_categories = ?
                    WHERE thread_id = ?
                """, (
                    datetime.now(),
                    json.dumps(state.dict()),
                    json.dumps(tool_categories or []),
                    thread_id
                ))
                
                # ä¿å­˜æ–°å¢çš„æ­¥éª¤
                existing_steps = conn.execute("""
                    SELECT COUNT(*) FROM conversation_steps WHERE thread_id = ?
                """, (thread_id,)).fetchone()[0]
                
                # åªä¿å­˜æ–°å¢çš„æ­¥éª¤
                new_steps = state.steps[existing_steps:]
                for i, step in enumerate(new_steps):
                    conn.execute("""
                        INSERT INTO conversation_steps 
                        (thread_id, step_index, step_data)
                        VALUES (?, ?, ?)
                    """, (
                        thread_id,
                        existing_steps + i,
                        json.dumps(step.dict())
                    ))
    
    def get_conversation_metadata(self, thread_id: str) -> Optional[ConversationMetadata]:
        """è·å–å¯¹è¯å…ƒæ•°æ®"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT thread_id, user_id, title, created_at, updated_at, tool_categories, tags
                FROM conversations WHERE thread_id = ?
            """, (thread_id,))
            
            row = cursor.fetchone()
            if not row:
                return None
            
            return ConversationMetadata(
                thread_id=row[0],
                user_id=row[1],
                title=row[2],
                created_at=datetime.fromisoformat(row[3]) if row[3] else None,
                updated_at=datetime.fromisoformat(row[4]) if row[4] else None,
                tool_categories=json.loads(row[5]) if row[5] else [],
                tags=json.loads(row[6]) if row[6] else []
            )
    
    def list_conversations(self, user_id: str = "default", 
                          tool_category: str = None,
                          limit: int = 50) -> List[ConversationMetadata]:
        """åˆ—å‡ºå¯¹è¯"""
        with sqlite3.connect(self.db_path) as conn:
            query = """
                SELECT thread_id, user_id, title, created_at, updated_at, tool_categories, tags
                FROM conversations 
                WHERE user_id = ?
            """
            params = [user_id]
            
            if tool_category:
                query += " AND tool_categories LIKE ?"
                params.append(f'%"{tool_category}"%')
            
            query += " ORDER BY updated_at DESC LIMIT ?"
            params.append(limit)
            
            cursor = conn.execute(query, params)
            
            conversations = []
            for row in cursor.fetchall():
                conversations.append(ConversationMetadata(
                    thread_id=row[0],
                    user_id=row[1],
                    title=row[2],
                    created_at=datetime.fromisoformat(row[3]) if row[3] else None,
                    updated_at=datetime.fromisoformat(row[4]) if row[4] else None,
                    tool_categories=json.loads(row[5]) if row[5] else [],
                    tags=json.loads(row[6]) if row[6] else []
                ))
            
            return conversations
    
    def delete_conversation(self, thread_id: str) -> bool:
        """åˆ é™¤å¯¹è¯"""
        with self._lock:
            with sqlite3.connect(self.db_path) as conn:
                # åˆ é™¤æ­¥éª¤
                conn.execute("DELETE FROM conversation_steps WHERE thread_id = ?", (thread_id,))
                
                # åˆ é™¤ä¸»è®°å½•
                cursor = conn.execute("DELETE FROM conversations WHERE thread_id = ?", (thread_id,))
                
                return cursor.rowcount > 0
    
    def add_tags(self, thread_id: str, tags: List[str]):
        """æ·»åŠ æ ‡ç­¾"""
        metadata = self.get_conversation_metadata(thread_id)
        if metadata:
            existing_tags = set(metadata.tags)
            existing_tags.update(tags)
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    UPDATE conversations SET tags = ?, updated_at = ?
                    WHERE thread_id = ?
                """, (
                    json.dumps(list(existing_tags)),
                    datetime.now(),
                    thread_id
                ))
    
    def update_conversation_title(self, thread_id: str, title: str):
        """æ›´æ–°å¯¹è¯æ ‡é¢˜"""
        with self._lock:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    UPDATE conversations SET title = ?, updated_at = ?
                    WHERE thread_id = ?
                """, (title, datetime.now(), thread_id))
                
                return cursor.rowcount > 0
    
    def search_conversations(self, query: str, user_id: str = "default") -> List[ConversationMetadata]:
        """æœç´¢å¯¹è¯"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT thread_id, user_id, title, created_at, updated_at, tool_categories, tags
                FROM conversations 
                WHERE user_id = ? AND (title LIKE ? OR state_data LIKE ?)
                ORDER BY updated_at DESC
            """, (user_id, f"%{query}%", f"%{query}%"))
            
            conversations = []
            for row in cursor.fetchall():
                conversations.append(ConversationMetadata(
                    thread_id=row[0],
                    user_id=row[1],
                    title=row[2],
                    created_at=datetime.fromisoformat(row[3]) if row[3] else None,
                    updated_at=datetime.fromisoformat(row[4]) if row[4] else None,
                    tool_categories=json.loads(row[5]) if row[5] else [],
                    tags=json.loads(row[6]) if row[6] else []
                ))
            
            return conversations
    
    def get_conversation_summary(self, thread_id: str) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        metadata = self.get_conversation_metadata(thread_id)
        state = self.load_conversation(thread_id)
        
        if not metadata or not state:
            return {}
        
        return {
            "thread_id": thread_id,
            "title": metadata.title,
            "question": state.question,
            "step_count": len(state.steps),
            "done": state.done,
            "tool_categories": metadata.tool_categories,
            "created_at": metadata.created_at.isoformat() if metadata.created_at else None,
            "updated_at": metadata.updated_at.isoformat() if metadata.updated_at else None,
            "final_answer": state.answer.get("final") if state.answer else None
        }
    
    async def run_conversation(self, user_input: str, session_id: str, max_steps: int = 12) -> Dict[str, Any]:
        """è¿è¡Œå¯¹è¯ï¼ˆéæµå¼ï¼‰"""
        result = {"steps": [], "final_answer": "", "success": False}
        
        async for step_data in self.run_conversation_stream(user_input, session_id, max_steps):
            if step_data["type"] == "step":
                result["steps"].append(step_data["data"])
            elif step_data["type"] == "final":
                result["final_answer"] = step_data["data"]["answer"]
                result["success"] = step_data["data"]["success"]
        
        return result
    
    async def run_conversation_stream(self, user_input: str, session_id: str, max_steps: int = 12):
        """è¿è¡Œå¯¹è¯ï¼ˆæµå¼è¾“å‡ºï¼‰"""
        from .schemas import validate_flexible_decide, get_flexible_system_prompt
        import json
        import os
        import requests
        
        # åŠ è½½æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
        state = self.load_conversation(session_id)
        if state is None:
            state = self.create_conversation(session_id, user_input, max_steps=max_steps)

        
        # è·å–å·¥å…·æ³¨å†Œè¡¨
        tool_registry = getattr(self, 'tool_registry', None)
        if not tool_registry:
            yield {
                "type": "error",
                "data": {"error": "å·¥å…·æ³¨å†Œè¡¨æœªåˆå§‹åŒ–"}
            }
            return
        
        # è·å–å¯ç”¨å·¥å…·
        available_tools = []
        for category in tool_registry.get_categories():
            provider = tool_registry.get_provider(category)
            if provider:
                for tool in provider.get_tools():
                    available_tools.append({
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.parameters
                    })
        
        step_count = 0
        while not state.done and step_count < max_steps:
            step_count += 1

            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = get_flexible_system_prompt()
            
            # æ„å»ºå¯¹è¯å†å²
            messages = [{"role": "system", "content": system_prompt}]
            messages.append({"role": "user", "content": user_input})
            
            # æ·»åŠ å†å²æ­¥éª¤ï¼ˆç¡®ä¿æ¶ˆæ¯æ ¼å¼æ­£ç¡®ï¼‰
            for step in state.steps:
                if hasattr(step, 'thought') and step.thought:
                    # æ·»åŠ assistantæ¶ˆæ¯
                    assistant_content = {
                        "step_type": getattr(step, 'step_type', 'reasoning'),
                        "thought": step.thought,
                        "action": getattr(step, 'action', None),
                        "args": getattr(step, 'args', {})
                    }
                    messages.append({"role": "assistant", "content": json.dumps(assistant_content, ensure_ascii=False)})
                    
                    # å¦‚æœæœ‰observationï¼Œæ·»åŠ å¯¹åº”çš„useræ¶ˆæ¯
                    if hasattr(step, 'observation') and step.observation:
                        messages.append({"role": "user", "content": f"è§‚å¯Ÿç»“æœ: {json.dumps(step.observation, ensure_ascii=False)}"})
            
            # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯assistantæ¶ˆæ¯ä¸”æ²¡æœ‰observationï¼Œæ·»åŠ ä¸€ä¸ªç»§ç»­çš„useræ¶ˆæ¯
            if len(messages) > 2 and messages[-1]["role"] == "assistant":
                last_step = state.steps[-1] if state.steps else None
                if last_step and (not hasattr(last_step, 'observation') or not last_step.observation):
                    if getattr(last_step, 'step_type', '') == 'reasoning':
                        messages.append({"role": "user", "content": "è¯·æ ¹æ®ä½ çš„æ¨ç†ç»“æœï¼Œæ‰§è¡Œä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚"})
            
            try:
                # è°ƒç”¨LLM
                llm_response = await self._call_llm(messages)
                
                # è§£æJSONå“åº”
                if isinstance(llm_response, str):
                    # æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    content = llm_response.strip()
                    if '{' in content:
                        start_idx = content.find('{')
                        brace_count = 0
                        end_idx = start_idx
                        
                        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                        for i in range(start_idx, len(content)):
                            if content[i] == '{':
                                brace_count += 1
                            elif content[i] == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    end_idx = i + 1
                                    break
                        
                        json_content = content[start_idx:end_idx]
                        print(f"ğŸ” æå–çš„JSONå†…å®¹: {json_content}")
                        
                        try:
                            llm_response = json.loads(json_content)
                        except json.JSONDecodeError as e:
                            print(f"ğŸ” JSONè§£æå¤±è´¥: {e}")
                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§é—®é¢˜
                            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªJSONå¯¹è±¡è¿åœ¨ä¸€èµ·
                            if json_content.count('}{') > 0:
                                # åˆ†å‰²å¤šä¸ªJSONå¯¹è±¡ï¼Œåªå–ç¬¬ä¸€ä¸ª
                                first_json = json_content.split('}{')[0] + '}'
                                print(f"ğŸ” ä¿®å¤åçš„JSON: {first_json}")
                                llm_response = json.loads(first_json)
                            else:
                                raise e
                    else:
                        llm_response = json.loads(llm_response)
                
                # è§£æå“åº”
                parsed = validate_flexible_decide(llm_response)
                
                # åˆ›å»ºæ­¥éª¤
                from .schemas import Step
                action = getattr(parsed, 'action', None)
                if action is None:
                    action = 'reasoning'  # é»˜è®¤åŠ¨ä½œ
                
                step = Step(
                    thought=parsed.thought,
                    action=action,
                    args=getattr(parsed, 'args', {}),
                    step_type=parsed.step_type
                )
                
                # è¾“å‡ºæ­¥éª¤ä¿¡æ¯
                step_data = {
                    "step_index": step_count,
                    "step_type": step.step_type,
                    "thought": step.thought,
                    "action": step.action,
                    "args": step.args
                }
                
                # å¦‚æœæ˜¯finishæ­¥éª¤ï¼Œæ·»åŠ answerå’Œrationale
                if step.step_type == "finish":
                    step_data["answer"] = getattr(parsed, 'answer', None)
                    step_data["rationale"] = getattr(parsed, 'rationale', None)
                
                yield {
                    "type": "step",
                    "data": step_data
                }
                
                # æ‰§è¡ŒåŠ¨ä½œ
                if step.action and step.action != "reasoning" and step.action != "finish":
                    try:
                        # æ‰§è¡Œå·¥å…·
                        observation = await tool_registry.execute_tool(step.action, **step.args)
                        step.observation = observation
                        
                        # è¾“å‡ºè§‚å¯Ÿç»“æœ
                        yield {
                            "type": "observation",
                            "data": {
                                "step_index": step_count,
                                "action": step.action,
                                "observation": observation
                            }
                        }
                        
                    except Exception as e:
                        step.observation = {"ok": False, "error": str(e)}
                        yield {
                            "type": "observation",
                            "data": {
                                "step_index": step_count,
                                "action": step.action,
                                "observation": step.observation
                            }
                        }
                
                # æ·»åŠ æ­¥éª¤åˆ°çŠ¶æ€
                state.steps.append(step)
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.action == "finish" or step.step_type == "finish":
                    state.done = True
                    # ä»finishæ­¥éª¤ä¸­æå–answerï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                    if hasattr(parsed, 'answer') and parsed.answer:
                        state.answer = {"answer": parsed.answer, "rationale": getattr(parsed, 'rationale', '')}
                    else:
                        state.answer = {"answer": step.args.get("answer", "ä»»åŠ¡å®Œæˆ"), "rationale": step.args.get("rationale", "")}
                    
                    # ä¿å­˜çŠ¶æ€
                    self.save_conversation(session_id, state)
                    
                    # è¾“å‡ºæœ€ç»ˆç»“æœ
                    yield {
                        "type": "final",
                        "data": {
                            "answer": state.answer,
                            "success": True,
                            "total_steps": len(state.steps)
                        }
                    }
                    return
                
                # å¦‚æœæ˜¯reasoningæ­¥éª¤ï¼Œç»§ç»­å¾ªç¯ç­‰å¾…ä¸‹ä¸€æ­¥action
                elif step.action == "reasoning" or step.step_type == "reasoning":
                    # è®¡ç®—è¿ç»­reasoningæ­¥éª¤æ•°
                    reasoning_count = 0
                    for s in reversed(state.steps):
                        if s.action == "reasoning" or s.step_type == "reasoning":
                            reasoning_count += 1
                        else:
                            break
                    
                    # å¦‚æœè¿ç»­reasoningè¶…è¿‡3æ¬¡ï¼Œç»™å‡ºè­¦å‘Šä½†ç»§ç»­
                    if reasoning_count >= 3:
                        yield {
                            "type": "warning",
                            "data": {
                                "message": "è¿ç»­æ¨ç†æ­¥éª¤è¾ƒå¤šï¼Œå»ºè®®æ‰§è¡Œå…·ä½“æ“ä½œ",
                                "reasoning_count": reasoning_count
                            }
                        }
                    
                    # ä¿å­˜çŠ¶æ€å¹¶ç»§ç»­å¾ªç¯
                    self.save_conversation(session_id, state)
                    continue
                
                # ä¿å­˜ä¸­é—´çŠ¶æ€
                self.save_conversation(session_id, state)
                
            except Exception as e:
                yield {
                    "type": "error",
                    "data": {
                        "step_index": step_count,
                        "error": str(e)
                    }
                }
                break
        
        # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°
        if step_count >= max_steps:
            state.done = True
            state.answer = "è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶"
            self.save_conversation(session_id, state)
            
            yield {
                "type": "final",
                "data": {
                    "answer": state.answer,
                    "success": False,
                    "total_steps": len(state.steps),
                    "reason": "max_steps_reached"
                }
            }
    
    async def _call_llm(self, messages):
        """è°ƒç”¨LLM"""
        import os
        import requests
        
        # è·å–LLMé…ç½®
        llm_provider = os.getenv("LLM_PROVIDER", "ollama")
        
        if llm_provider == "ollama":
            url = f"{os.getenv('OLLAMA_BASE', 'http://localhost:11434')}/api/chat"
            payload = {
                "model": os.getenv("OLLAMA_MODEL", "gpt-oss:20b"),
                "messages": messages,
                "stream": False,
                "options": {"temperature": 0.2}
            }
            
            # ç¦ç”¨ä»£ç†
            session = requests.Session()
            session.trust_env = False
            
            print(f"ğŸ” è°ƒç”¨LLM - URL: {url}")
            print(f"ğŸ” è°ƒç”¨LLM - Payload: {payload}")
            
            response = session.post(url, json=payload, timeout=60)
            response.raise_for_status()
            data = response.json()
            
            print(f"ğŸ” LLMå“åº”: {data}")
            
            if isinstance(data, dict) and "message" in data:
                content = data["message"]["content"]
                print(f"ğŸ” æå–çš„å†…å®¹: {content}")
                return content
            print("ğŸ” æœªæ‰¾åˆ°messageå­—æ®µï¼Œè¿”å›ç©ºJSON")
            return "{}"
        else:
            # OpenAI API
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}"},
                json={
                    "model": os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                    "temperature": 0.2,
                    "messages": messages,
                    "response_format": {"type": "json_object"}
                },
                timeout=60
            )
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]


# å…¨å±€å¯¹è¯ç®¡ç†å™¨å®ä¾‹
_global_conversation_manager = None


def get_conversation_manager() -> ConversationManager:
    """è·å–å…¨å±€å¯¹è¯ç®¡ç†å™¨"""
    global _global_conversation_manager
    if _global_conversation_manager is None:
        _global_conversation_manager = ConversationManager()
    return _global_conversation_manager